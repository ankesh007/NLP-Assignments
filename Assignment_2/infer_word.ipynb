{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "import nltk\n",
    "import os\n",
    "import utils\n",
    "from random import shuffle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_data_file='data/eval_data.txt'\n",
    "eval_words_file='data/eval_data.txt.td'\n",
    "lemmatizer=WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21918\n"
     ]
    }
   ],
   "source": [
    "reader=open(eval_words_file,'r')\n",
    "eval_words_list=[]\n",
    "for line in reader:\n",
    "    tok_line=line.strip().split(\" \")\n",
    "    x=len(tok_line)\n",
    "    for i in range(x):\n",
    "        tok_line[i]=tok_line[i].split(\":\")[-1]\n",
    "    eval_words_list.append(tok_line)\n",
    "print(len(eval_words_list))\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43836 21918\n",
      "['the', 'particulars', 'of', 'your', 'plans', 'i', 'neither'] know\n",
      "['or', 'seek', 'to', 'know'] know\n"
     ]
    }
   ],
   "source": [
    "reader=open(eval_data_file,'r')\n",
    "context_list=[]\n",
    "y=[]\n",
    "\n",
    "for line in reader:\n",
    "    tok_line=line.strip().split(\"<<target>>\")\n",
    "    context=gensim.utils.simple_preprocess(tok_line[0],min_len=1)\n",
    "    x=len(context)\n",
    "    \n",
    "    y.append(tok_line[1].split(\":\")[-1])\n",
    "    context2=gensim.utils.simple_preprocess(tok_line[1])\n",
    "\n",
    "    if len(context2)>0:\n",
    "        context2.pop()\n",
    "    \n",
    "    context_list.append(context)\n",
    "    context_list.append(context2)\n",
    "print(len(context_list),len(y))\n",
    "print(context_list[0],y[0])\n",
    "print(context_list[1],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "eval_words_list=utils.lemmatize(eval_words_list)\n",
    "context_list=utils.lemmatize(context_list)\n",
    "y=utils.lemmatize_1d(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(arr,file):\n",
    "    with open(file,'w') as f:\n",
    "        for line in arr:\n",
    "            st=\" \".join([str(x) for x in line])\n",
    "            print(st,file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(func,save_path,flag=False,hits=2000,context_win=2,upto=2000):\n",
    "\n",
    "    mrr=0\n",
    "    mr=0\n",
    "    ranking=[]\n",
    "\n",
    "    if flag==True:\n",
    "        upto=len(eval_words_list)\n",
    "\n",
    "    for i in range(upto):\n",
    "        if i%100==0:\n",
    "            print(mrr/(i+1),mr*1.0/(i+1),i)\n",
    "        context1=context_list[2*i]\n",
    "        context2=context_list[2*i+1]\n",
    "        x1=len(context1)\n",
    "        x2=len(context2)\n",
    "        if x1>context_win:\n",
    "            context1=context1[x1-context_win:x1]\n",
    "        if x2>context_win:\n",
    "            context2=context2[0:context_win]\n",
    "        \n",
    "        context=context1+context2\n",
    "        word=y[i]\n",
    "        val=func(context,topn=hits)\n",
    "        local_rank=[]\n",
    "        mapper={}\n",
    "        mapper_count={}\n",
    "        for w in eval_words_list[i]:\n",
    "            mapper[w]=0\n",
    "            if w not in mapper_count:\n",
    "                mapper_count[w]=0\n",
    "            mapper_count[w]+=1\n",
    "\n",
    "        count=1\n",
    "        if val is not None:\n",
    "            for j in range(len(val)):\n",
    "                if val[j][0] in mapper:\n",
    "                    mapper[val[j][0]]=count\n",
    "                    count+=mapper_count[val[j][0]]\n",
    "\n",
    "        temp=[]\n",
    "        for w in eval_words_list[i]:\n",
    "            if mapper[w]==0:\n",
    "                temp.append(w)\n",
    "        shuffle(temp)\n",
    "        \n",
    "        for w in temp:\n",
    "            if mapper[w]==0:\n",
    "                mapper[w]=count\n",
    "                count+=mapper_count[w]\n",
    "\n",
    "        for w in eval_words_list[i]:\n",
    "            local_rank.append(mapper[w])\n",
    "            mapper[w]+=1\n",
    "        ranking.append(local_rank)\n",
    "\n",
    "        if word not in mapper:\n",
    "            print (word)\n",
    "            print (eval_words_list[i])\n",
    "            print (mapper)\n",
    "        \n",
    "        mr+=(mapper[word]-1)\n",
    "        mrr+=1.0/(mapper[word]-1)\n",
    "    write_file(ranking,save_path)\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(path,output,flag=False,hits=2000,context_win=1):\n",
    "    model_path=path\n",
    "    model=utils.load_pickle(model_path)\n",
    "    x=time.time()\n",
    "    \n",
    "    t=func(model.predict_output_word,output,flag=flag,hits=hits,context_win=context_win)\n",
    "    print(time.time()-x)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getC(w1,w2,ds):\n",
    "    key=w1+\"_\"+w2\n",
    "    if key in ds:\n",
    "        return ds[key]\n",
    "    return 0\n",
    "    \n",
    "def counter(ds,word,context,begin):\n",
    "    x=len(context)\n",
    "    count=0.0\n",
    "    wt=1.0\n",
    "\n",
    "    if begin==1:\n",
    "        for i in range(min(x,2)):\n",
    "            count+=getC(word,context[i],ds)*wt\n",
    "            wt/=2\n",
    "    else:\n",
    "        for i in range(x-1,max(0,x-3),-1):\n",
    "            count+=getC(word,context[i],ds)*wt\n",
    "            wt/=2\n",
    "    return count\n",
    "\n",
    "def rerank(rank_list,context_list,eval_words_list,rr=30):\n",
    "    le=len(rank_list)\n",
    "    aux_ds=utils.load_pickle(filename=\"aux_ds.pkl\")\n",
    "    for i in range(le):\n",
    "        imp_words=[]\n",
    "        lee=len(rank_list[i])\n",
    "        for j in range(lee):\n",
    "            if rank_list[i][j]<rr:\n",
    "                imp_words.append((eval_words_list[i][j],rank_list[i][j],j))\n",
    "        new_lis=[]\n",
    "        for w in imp_words:\n",
    "            word=w[0]\n",
    "            rank=w[1]\n",
    "            pos=w[2]\n",
    "            count=0\n",
    "            count+=counter(aux_ds,word,context_list[2*i],0)\n",
    "            count+=counter(aux_ds,word,context_list[2*i+1],1)\n",
    "            new_lis.append((count,-rank,pos))\n",
    "#         print(new_lis)\n",
    "        new_lis=sorted(new_lis,reverse=True)\n",
    "#         print(new_lis)\n",
    "        c=0\n",
    "        for entry in new_lis:\n",
    "            c+=1\n",
    "            pos=entry[2]\n",
    "            rank_list[i][pos]=c\n",
    "    write_file(arr=rank_list,file=\"rerank.txt\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pt(t):\n",
    "    for i in range(5):\n",
    "        print(context_list[2*i],context_list[2*i+1],y[i])\n",
    "        temp=list(zip(t[i],eval_words_list[i]))\n",
    "        print(sorted(temp)[0:20])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_path='./sg_emb150_ep10.pkl'\n",
    "# out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=1)\n",
    "# pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_path='./sg_emb150_ep10.pkl'\n",
    "# out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=2)\n",
    "# pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0\n",
      "0.2902408292699335 23.07920792079208 100\n",
      "0.2571600272191281 29.751243781094526 200\n",
      "0.24594661801831413 32.548172757475086 300\n",
      "0.23664324182659066 33.46633416458853 400\n",
      "0.22811226259011527 35.327345309381236 500\n",
      "0.23298508173925106 34.577371048252914 600\n",
      "0.23223073559454002 34.17403708987161 700\n",
      "0.23144765889580976 35.114856429463174 800\n",
      "0.2363921401743288 34.52719200887903 900\n",
      "0.23557568694135061 34.17682317682318 1000\n",
      "0.2359158561277459 34.51589464123524 1100\n",
      "0.24101726406552432 33.62614487926728 1200\n",
      "0.245953615127981 33.169100691775554 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1150210/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:859: UserWarning: All the input context words are out-of-vocabulary for the current model.\n",
      "  warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24384719832704868 33.47466095645967 1400\n",
      "0.24645255931511773 33.16255829447035 1500\n",
      "0.2462441319352095 32.70143660212367 1600\n",
      "0.2480302398569263 32.16460905349794 1700\n",
      "0.24831224355708525 31.814547473625762 1800\n",
      "0.2489393063697618 31.70541820094687 1900\n",
      "36.10829997062683\n",
      "2000\n",
      "['the', 'particulars', 'of', 'your', 'plans', 'i', 'neither'] ['or', 'seek', 'to', 'know'] know\n",
      "[(1, 'do'), (2, 'think'), (3, 'know'), (4, 'see'), (5, 'get'), (6, 'go'), (7, 'say'), (8, 'find'), (9, 'lose'), (10, 'knew'), (11, 'believe'), (12, 'come'), (13, 'tell'), (14, 'leave'), (15, 'understand'), (16, 'give'), (17, 'expect'), (18, 'take'), (19, 'have'), (20, 'keep')]\n",
      "\n",
      "['while', 'i', 'am', 'very', 'anxious', 'that', 'any', 'great', 'disaster', 'or', 'the', 'capture', 'of', 'our', 'men', 'in', 'great', 'numbers'] ['be', 'avoided', 'know', 'these', 'points', 'are', 'less', 'likely', 'to', 'escape', 'your', 'attention', 'than', 'they', 'would', 'be', 'mine'] shall\n",
      "[(1, 'could'), (2, 'would'), (3, 'should'), (4, 'might'), (5, 'must'), (6, 'will'), (7, 'may'), (8, 'shall'), (9, 'liable'), (10, 'prepared'), (11, 'can'), (12, 'means'), (13, 'ought'), (14, 'told'), (15, 'surprised'), (16, 'six'), (17, 'genii'), (18, 'terms'), (19, 'leave'), (20, 'designs')]\n",
      "\n",
      "['if', 'there', 'is', 'anything', 'wanting', 'which', 'is', 'within', 'my', 'power', 'to'] ['do', 'not', 'fail', 'to', 'let', 'me', 'know', 'it'] give\n",
      "[(1, 'do'), (2, 'go'), (3, 'know'), (4, 'see'), (5, 'come'), (6, 'believe'), (7, 'say'), (8, 'find'), (9, 'get'), (10, 'leave'), (11, 'take'), (12, 'make'), (13, 'give'), (14, 'keep'), (15, 'save'), (16, 'let'), (17, 'appear'), (18, 'expect'), (19, 'follow'), (20, 'remember')]\n",
      "\n",
      "['your', 'request', 'for', 'eighty', 'dollars', 'i', 'do'] ['think', 'it', 'best', 'to', 'comply', 'with', 'now'] not\n",
      "[(1, 'did'), (2, 'do'), (3, 'anything'), (4, 'want'), (5, 'not'), (6, 'never'), (7, 'well'), (8, 'does'), (9, 'here'), (10, 'rather'), (11, 'long'), (12, 'still'), (13, 'anyway'), (14, 'neither'), (15, 'nicely'), (16, 'actually'), (17, 'bly'), (18, 'indignantly'), (19, 'often'), (20, 'soon')]\n",
      "\n",
      "['at', 'the', 'various', 'times', 'when', 'i', 'have', 'helped', 'you', 'a', 'little', 'you', 'have', 'said', 'to', 'me', 'we', 'can'] ['along', 'very', 'well', 'now', 'but', 'in', 'very', 'short', 'time', 'find', 'you', 'in', 'the', 'same', 'difficulty', 'again'] get\n",
      "[(1, 'get'), (2, 'find'), (3, 'go'), (4, 'got'), (5, 'come'), (6, 'see'), (7, 'do'), (8, 'take'), (9, 'know'), (10, 'keep'), (11, 'say'), (12, 'run'), (13, 'make'), (14, 'leave'), (15, 'give'), (16, 'happen'), (17, 'be'), (18, 'remember'), (19, 'getting'), (20, 'settle')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path='./sg_pret_emb300_ep10.pkl'\n",
    "out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=2)\n",
    "print(len(out))\n",
    "pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "rerank(out,context_list=context_list,eval_words_list=eval_words_list,rr=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0\n",
      "0.2893944782262512 25.237623762376238 100\n",
      "0.2572403744650303 29.601990049751244 200\n",
      "0.2459740348229016 32.21926910299003 300\n",
      "0.23662566384313344 33.576059850374065 400\n",
      "0.22811217196984215 34.510978043912175 500\n",
      "0.233049795218528 33.15640599001664 600\n",
      "0.2326048361356494 31.80599144079886 700\n",
      "0.23189910073620068 32.45692883895131 800\n",
      "0.23686077502706493 31.7857935627081 900\n",
      "0.23600255860732838 31.929070929070928 1000\n",
      "0.2363320654030125 32.473206176203455 1100\n",
      "0.24141425782336312 31.825978351373855 1200\n",
      "0.2463044484498575 31.448885472713297 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1150210/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:859: UserWarning: All the input context words are out-of-vocabulary for the current model.\n",
      "  warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2442056183290529 31.705924339757317 1400\n",
      "0.2468021207520262 31.614257161892073 1500\n",
      "0.2465860848253774 31.195502810743285 1600\n",
      "0.2483167239071588 30.951793062904173 1700\n",
      "0.24858488105880908 30.856191004997225 1800\n",
      "0.24914825817683459 31.048395581273013 1900\n",
      "CPU times: user 6min 7s, sys: 1min 21s, total: 7min 29s\n",
      "Wall time: 35.7 s\n",
      "['the', 'particulars', 'of', 'your', 'plans', 'i', 'neither'] ['or', 'seek', 'to', 'know'] know\n",
      "[(1, 'do'), (2, 'get'), (3, 'lose'), (4, 'go'), (5, 'see'), (6, 'come'), (7, 'think'), (8, 'know'), (9, 'find'), (10, 'appear'), (11, 'say'), (12, 'expect'), (13, 'take'), (14, 'give'), (15, 'leave'), (16, 'be'), (17, 'make'), (18, 'have'), (19, 'remove'), (20, 'knew')]\n",
      "['while', 'i', 'am', 'very', 'anxious', 'that', 'any', 'great', 'disaster', 'or', 'the', 'capture', 'of', 'our', 'men', 'in', 'great', 'numbers'] ['be', 'avoided', 'know', 'these', 'points', 'are', 'less', 'likely', 'to', 'escape', 'your', 'attention', 'than', 'they', 'would', 'be', 'mine'] shall\n",
      "[(1, 'would'), (2, 'could'), (3, 'might'), (4, 'should'), (5, 'must'), (6, 'will'), (7, 'may'), (8, 'shall'), (9, 'can'), (10, 'liable'), (11, 'means'), (12, 'told'), (13, 'genii'), (14, 'prepared'), (15, 'leave'), (16, 'ought'), (17, 'say'), (18, 'friendship'), (19, 'surprised'), (20, 'terms')]\n",
      "['if', 'there', 'is', 'anything', 'wanting', 'which', 'is', 'within', 'my', 'power', 'to'] ['do', 'not', 'fail', 'to', 'let', 'me', 'know', 'it'] give\n",
      "[(1, 'know'), (2, 'do'), (3, 'come'), (4, 'see'), (5, 'go'), (6, 'say'), (7, 'get'), (8, 'take'), (9, 'make'), (10, 'find'), (11, 'leave'), (12, 'keep'), (13, 'expect'), (14, 'give'), (15, 'follow'), (16, 'be'), (17, 'save'), (18, 'believe'), (19, 'happen'), (20, 'appear')]\n",
      "['your', 'request', 'for', 'eighty', 'dollars', 'i', 'do'] ['think', 'it', 'best', 'to', 'comply', 'with', 'now'] not\n",
      "[(1, 'anything'), (2, 'do'), (3, 'not'), (4, 'did'), (5, 'want'), (6, 'well'), (7, 'does'), (8, 'never'), (9, 'here'), (10, 'long'), (11, 'still'), (12, 'actually'), (13, 'neither'), (14, 'rather'), (15, 'indignantly'), (16, 'anyway'), (17, 'possibly'), (18, 'soon'), (19, 'often'), (20, 'earnestly')]\n",
      "['at', 'the', 'various', 'times', 'when', 'i', 'have', 'helped', 'you', 'a', 'little', 'you', 'have', 'said', 'to', 'me', 'we', 'can'] ['along', 'very', 'well', 'now', 'but', 'in', 'very', 'short', 'time', 'find', 'you', 'in', 'the', 'same', 'difficulty', 'again'] get\n",
      "[(1, 'get'), (2, 'go'), (3, 'find'), (4, 'see'), (5, 'got'), (6, 'come'), (7, 'know'), (8, 'do'), (9, 'keep'), (10, 'take'), (11, 'make'), (12, 'run'), (13, 'remember'), (14, 'give'), (15, 'leave'), (16, 'getting'), (17, 'say'), (18, 'expect'), (19, 'be'), (20, 'have')]\n"
     ]
    }
   ],
   "source": [
    "model_path='./sg_pret_emb300_ep10.pkl'\n",
    "out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=2)\n",
    "pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0\n",
      "0.26391612477753434 27.128712871287128 100\n",
      "0.2376854486029815 30.199004975124378 200\n",
      "0.2217697262875314 31.259136212624586 300\n",
      "0.21616044145629432 31.25935162094763 400\n",
      "0.2070474066972291 32.187624750499005 500\n",
      "0.2120257312157065 31.111480865224625 600\n",
      "0.20839003355376629 30.03994293865906 700\n",
      "0.20771398907207983 31.18227215980025 800\n",
      "0.21287780316937027 30.200887902330745 900\n",
      "0.21344547699402405 30.285714285714285 1000\n",
      "0.21301072857546782 30.52043596730245 1100\n",
      "0.2181378429937186 29.98001665278934 1200\n",
      "0.2230251622775511 29.63182167563413 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1150210/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:859: UserWarning: All the input context words are out-of-vocabulary for the current model.\n",
      "  warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22219956340404148 30.11277658815132 1400\n",
      "0.22650734193442826 30.109926715522985 1500\n",
      "0.2259671032940872 29.75202998126171 1600\n",
      "0.22744967892824336 29.59376837154615 1700\n",
      "0.22904959248349605 29.56857301499167 1800\n",
      "0.2278908114456888 29.56233561283535 1900\n",
      "CPU times: user 5min 10s, sys: 1min 10s, total: 6min 20s\n",
      "Wall time: 30.4 s\n",
      "['the', 'particular', 'of', 'your', 'plan', 'i', 'neither'] ['or', 'seek', 'to', 'know'] know\n",
      "[(1, 'do'), (2, 'get'), (3, 'lose'), (4, 'go'), (5, 'see'), (6, 'come'), (7, 'think'), (8, 'know'), (9, 'find'), (10, 'appear'), (11, 'say'), (12, 'expect'), (13, 'take'), (14, 'give'), (15, 'leave'), (16, 'be'), (17, 'make'), (18, 'have'), (19, 'remove'), (20, 'knew')]\n",
      "['while', 'i', 'am', 'very', 'anxious', 'that', 'any', 'great', 'disaster', 'or', 'the', 'capture', 'of', 'our', 'men', 'in', 'great', 'number'] ['be', 'avoided', 'know', 'these', 'point', 'are', 'le', 'likely', 'to', 'escape', 'your', 'attention', 'than', 'they', 'would', 'be', 'mine'] shall\n",
      "[(1, 'would'), (2, 'could'), (3, 'might'), (4, 'should'), (5, 'must'), (6, 'will'), (7, 'may'), (8, 'shall'), (9, 'can'), (10, 'liable'), (11, 'mean'), (12, 'told'), (13, 'genius'), (14, 'prepared'), (15, 'leave'), (16, 'ought'), (17, 'say'), (18, 'friendship'), (19, 'surprised'), (20, 'term')]\n",
      "['if', 'there', 'is', 'anything', 'wanting', 'which', 'is', 'within', 'my', 'power', 'to'] ['do', 'not', 'fail', 'to', 'let', 'me', 'know', 'it'] give\n",
      "[(1, 'know'), (2, 'do'), (3, 'come'), (4, 'see'), (5, 'go'), (6, 'say'), (7, 'get'), (8, 'take'), (9, 'make'), (10, 'find'), (11, 'leave'), (12, 'keep'), (13, 'expect'), (14, 'give'), (15, 'follow'), (16, 'be'), (17, 'save'), (18, 'believe'), (19, 'happen'), (20, 'appear')]\n",
      "['your', 'request', 'for', 'eighty', 'dollar', 'i', 'do'] ['think', 'it', 'best', 'to', 'comply', 'with', 'now'] not\n",
      "[(1, 'anything'), (2, 'do'), (3, 'not'), (4, 'did'), (5, 'want'), (6, 'well'), (7, 'doe'), (8, 'never'), (9, 'here'), (10, 'long'), (11, 'still'), (12, 'actually'), (13, 'neither'), (14, 'rather'), (15, 'indignantly'), (16, 'anyway'), (17, 'possibly'), (18, 'soon'), (19, 'often'), (20, 'earnestly')]\n",
      "['at', 'the', 'various', 'time', 'when', 'i', 'have', 'helped', 'you', 'a', 'little', 'you', 'have', 'said', 'to', 'me', 'we', 'can'] ['along', 'very', 'well', 'now', 'but', 'in', 'very', 'short', 'time', 'find', 'you', 'in', 'the', 'same', 'difficulty', 'again'] get\n",
      "[(1, 'get'), (2, 'go'), (3, 'find'), (4, 'see'), (5, 'got'), (6, 'come'), (7, 'know'), (8, 'do'), (9, 'keep'), (10, 'take'), (11, 'make'), (12, 'run'), (13, 'remember'), (14, 'give'), (15, 'leave'), (16, 'getting'), (17, 'say'), (18, 'expect'), (19, 'be'), (20, 'have')]\n"
     ]
    }
   ],
   "source": [
    "model_path='./lemm_sg_emb200_ep10.pkl'\n",
    "out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=2)\n",
    "pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0\n",
      "0.25688693696160253 23.07920792079208 100\n",
      "0.23925517310530106 28.29353233830846 200\n",
      "0.22493485082417478 30.837209302325583 300\n",
      "0.2162244229882309 32.71321695760599 400\n",
      "0.21029776755662932 32.82235528942116 500\n",
      "0.21343685875401025 31.948419301164726 600\n",
      "0.21098447743034146 31.40085592011412 700\n",
      "0.2086222644706398 32.07116104868914 800\n",
      "0.21457922495151247 31.519422863485016 900\n",
      "0.21478662947921515 31.3996003996004 1000\n",
      "0.21514307230787305 31.819255222524976 1100\n",
      "0.22012835862880784 30.896752706078267 1200\n",
      "0.22382954537927022 30.911606456571867 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1150210/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:859: UserWarning: All the input context words are out-of-vocabulary for the current model.\n",
      "  warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22331252935284046 31.37330478229836 1400\n",
      "0.22626013597101433 31.5236508994004 1500\n",
      "0.2254713290461498 31.245471580262336 1600\n",
      "0.22660964028781114 30.95767195767196 1700\n",
      "0.22705867404726635 30.89339255968906 1800\n",
      "0.22597835221040954 30.711730668069436 1900\n",
      "CPU times: user 5min 12s, sys: 1min 7s, total: 6min 19s\n",
      "Wall time: 29.9 s\n",
      "['the', 'particular', 'of', 'your', 'plan', 'i', 'neither'] ['or', 'seek', 'to', 'know'] know\n",
      "[(1, 'do'), (2, 'get'), (3, 'lose'), (4, 'go'), (5, 'see'), (6, 'come'), (7, 'think'), (8, 'know'), (9, 'find'), (10, 'appear'), (11, 'say'), (12, 'expect'), (13, 'take'), (14, 'give'), (15, 'leave'), (16, 'be'), (17, 'make'), (18, 'have'), (19, 'remove'), (20, 'knew')]\n",
      "['while', 'i', 'am', 'very', 'anxious', 'that', 'any', 'great', 'disaster', 'or', 'the', 'capture', 'of', 'our', 'men', 'in', 'great', 'number'] ['be', 'avoided', 'know', 'these', 'point', 'are', 'le', 'likely', 'to', 'escape', 'your', 'attention', 'than', 'they', 'would', 'be', 'mine'] shall\n",
      "[(1, 'would'), (2, 'could'), (3, 'might'), (4, 'should'), (5, 'must'), (6, 'will'), (7, 'may'), (8, 'shall'), (9, 'can'), (10, 'liable'), (11, 'mean'), (12, 'told'), (13, 'genius'), (14, 'prepared'), (15, 'leave'), (16, 'ought'), (17, 'say'), (18, 'friendship'), (19, 'surprised'), (20, 'term')]\n",
      "['if', 'there', 'is', 'anything', 'wanting', 'which', 'is', 'within', 'my', 'power', 'to'] ['do', 'not', 'fail', 'to', 'let', 'me', 'know', 'it'] give\n",
      "[(1, 'know'), (2, 'do'), (3, 'come'), (4, 'see'), (5, 'go'), (6, 'say'), (7, 'get'), (8, 'take'), (9, 'make'), (10, 'find'), (11, 'leave'), (12, 'keep'), (13, 'expect'), (14, 'give'), (15, 'follow'), (16, 'be'), (17, 'save'), (18, 'believe'), (19, 'happen'), (20, 'appear')]\n",
      "['your', 'request', 'for', 'eighty', 'dollar', 'i', 'do'] ['think', 'it', 'best', 'to', 'comply', 'with', 'now'] not\n",
      "[(1, 'anything'), (2, 'do'), (3, 'not'), (4, 'did'), (5, 'want'), (6, 'well'), (7, 'doe'), (8, 'never'), (9, 'here'), (10, 'long'), (11, 'still'), (12, 'actually'), (13, 'neither'), (14, 'rather'), (15, 'indignantly'), (16, 'anyway'), (17, 'possibly'), (18, 'soon'), (19, 'often'), (20, 'earnestly')]\n",
      "['at', 'the', 'various', 'time', 'when', 'i', 'have', 'helped', 'you', 'a', 'little', 'you', 'have', 'said', 'to', 'me', 'we', 'can'] ['along', 'very', 'well', 'now', 'but', 'in', 'very', 'short', 'time', 'find', 'you', 'in', 'the', 'same', 'difficulty', 'again'] get\n",
      "[(1, 'get'), (2, 'go'), (3, 'find'), (4, 'see'), (5, 'got'), (6, 'come'), (7, 'know'), (8, 'do'), (9, 'keep'), (10, 'take'), (11, 'make'), (12, 'run'), (13, 'remember'), (14, 'give'), (15, 'leave'), (16, 'getting'), (17, 'say'), (18, 'expect'), (19, 'be'), (20, 'have')]\n"
     ]
    }
   ],
   "source": [
    "model_path='./lemm_sg_emb300_ep10.pkl'\n",
    "out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=2)\n",
    "pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0\n",
      "0.2676649835511454 24.752475247524753 100\n",
      "0.24828999576880043 26.154228855721392 200\n",
      "0.2303409385191886 28.205980066445182 300\n",
      "0.22314654114821855 28.453865336658353 400\n",
      "0.21036206838861563 28.201596806387226 500\n",
      "0.213716530519465 27.183028286189685 600\n",
      "0.21143448900197412 26.024251069900142 700\n",
      "0.21092401311474912 26.436953807740323 800\n",
      "0.21800731786213765 25.964483906770255 900\n",
      "0.22038235373743267 25.829170829170828 1000\n",
      "0.21948239261414645 26.26975476839237 1100\n",
      "0.22326402501897627 26.074937552039966 1200\n",
      "0.2276445056252417 25.983858570330515 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1150210/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:859: UserWarning: All the input context words are out-of-vocabulary for the current model.\n",
      "  warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22830395610309423 26.422555317630263 1400\n",
      "0.2307463904850185 26.421718854097268 1500\n",
      "0.23027949509473006 26.14303560274828 1600\n",
      "0.23200635779432546 25.890064667842445 1700\n",
      "0.23226842778203236 25.932259855635756 1800\n",
      "0.23162991790499343 26.042083114150447 1900\n",
      "CPU times: user 5min 46s, sys: 1min 17s, total: 7min 3s\n",
      "Wall time: 33.7 s\n",
      "['the', 'particular', 'of', 'your', 'plan', 'i', 'neither'] ['or', 'seek', 'to', 'know'] know\n",
      "[(1, 'do'), (2, 'get'), (3, 'lose'), (4, 'go'), (5, 'see'), (6, 'come'), (7, 'think'), (8, 'know'), (9, 'find'), (10, 'appear'), (11, 'say'), (12, 'expect'), (13, 'take'), (14, 'give'), (15, 'leave'), (16, 'be'), (17, 'make'), (18, 'have'), (19, 'remove'), (20, 'knew')]\n",
      "['while', 'i', 'am', 'very', 'anxious', 'that', 'any', 'great', 'disaster', 'or', 'the', 'capture', 'of', 'our', 'men', 'in', 'great', 'number'] ['be', 'avoided', 'know', 'these', 'point', 'are', 'le', 'likely', 'to', 'escape', 'your', 'attention', 'than', 'they', 'would', 'be', 'mine'] shall\n",
      "[(1, 'would'), (2, 'could'), (3, 'might'), (4, 'should'), (5, 'must'), (6, 'will'), (7, 'may'), (8, 'shall'), (9, 'can'), (10, 'liable'), (11, 'mean'), (12, 'told'), (13, 'genius'), (14, 'prepared'), (15, 'leave'), (16, 'ought'), (17, 'say'), (18, 'friendship'), (19, 'surprised'), (20, 'term')]\n",
      "['if', 'there', 'is', 'anything', 'wanting', 'which', 'is', 'within', 'my', 'power', 'to'] ['do', 'not', 'fail', 'to', 'let', 'me', 'know', 'it'] give\n",
      "[(1, 'know'), (2, 'do'), (3, 'come'), (4, 'see'), (5, 'go'), (6, 'say'), (7, 'get'), (8, 'take'), (9, 'make'), (10, 'find'), (11, 'leave'), (12, 'keep'), (13, 'expect'), (14, 'give'), (15, 'follow'), (16, 'be'), (17, 'save'), (18, 'believe'), (19, 'happen'), (20, 'appear')]\n",
      "['your', 'request', 'for', 'eighty', 'dollar', 'i', 'do'] ['think', 'it', 'best', 'to', 'comply', 'with', 'now'] not\n",
      "[(1, 'anything'), (2, 'do'), (3, 'not'), (4, 'did'), (5, 'want'), (6, 'well'), (7, 'doe'), (8, 'never'), (9, 'here'), (10, 'long'), (11, 'still'), (12, 'actually'), (13, 'neither'), (14, 'rather'), (15, 'indignantly'), (16, 'anyway'), (17, 'possibly'), (18, 'soon'), (19, 'often'), (20, 'earnestly')]\n",
      "['at', 'the', 'various', 'time', 'when', 'i', 'have', 'helped', 'you', 'a', 'little', 'you', 'have', 'said', 'to', 'me', 'we', 'can'] ['along', 'very', 'well', 'now', 'but', 'in', 'very', 'short', 'time', 'find', 'you', 'in', 'the', 'same', 'difficulty', 'again'] get\n",
      "[(1, 'get'), (2, 'go'), (3, 'find'), (4, 'see'), (5, 'got'), (6, 'come'), (7, 'know'), (8, 'do'), (9, 'keep'), (10, 'take'), (11, 'make'), (12, 'run'), (13, 'remember'), (14, 'give'), (15, 'leave'), (16, 'getting'), (17, 'say'), (18, 'expect'), (19, 'be'), (20, 'have')]\n"
     ]
    }
   ],
   "source": [
    "model_path='./lemm_pre_sg_emb300_ep10.pkl'\n",
    "out=run_eval(model_path,'out.txt',flag=False,hits=2000,context_win=2)\n",
    "pt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aa(a):\n",
    "    return 2*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 16.2 µs\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "%time a=aa(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pt(t):\n",
    "    for i in range(5):\n",
    "        print(context_list[2*i],context_list[2*i+1],y[i])\n",
    "        temp=list(zip(t[i],eval_words_list[i]))\n",
    "        print(sorted(temp)[0:20])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
