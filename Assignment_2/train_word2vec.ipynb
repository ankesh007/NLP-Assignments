{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "import nltk\n",
    "import os\n",
    "import utils\n",
    "from gensim.models import Word2Vec,FastText\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir=\"data/dataset/\"\n",
    "pretrained_vectors='data/GoogleNews-vectors-negative300.bin.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dataset/text_3.txt\n",
      "data/dataset/text_7.txt\n",
      "data/dataset/text_2.txt\n",
      "data/dataset/text_11.txt\n",
      "data/dataset/text_8.txt\n",
      "data/dataset/text_6.txt\n",
      "data/dataset/text_10.txt\n",
      "data/dataset/text_4.txt\n",
      "data/dataset/text_9.txt\n",
      "data/dataset/text_1.txt\n",
      "data/dataset/text_5.txt\n",
      "data/dataset/text_13.txt\n",
      "data/dataset/text_12.txt\n",
      "93093\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "for dir,subdir,files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        file_path=os.path.join(dir,file)\n",
    "        x+=utils.read_data(file_path)\n",
    "        print(file_path)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize(lines):\n",
    "    new_lines=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    counter=0\n",
    "    for line in lines:\n",
    "        counter+=1\n",
    "        if(counter%10000==0):\n",
    "            print(counter)\n",
    "        new_line=[]\n",
    "        for word in line:\n",
    "            new_line.append(lemmatizer.lemmatize(word))\n",
    "        new_lines.append(new_line)\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemm_x=lemmatize(x)\n",
    "# utils.dump_pickle(lemm_x,\"lemm_x.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = Word2Vec(size=300, min_count=1,workers=4,sg=1)\n",
    "model_2.build_vocab(x)\n",
    "total_examples = model_2.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93093\n",
      "27747\n",
      "['the', 'lay', 'man', 'sermon', 'upon', 'late', 'storm', 'held', 'forth', 'at']\n"
     ]
    }
   ],
   "source": [
    "print(total_examples)\n",
    "print(len(list(model_2.wv.vocab.keys())))\n",
    "print(list(model_2.wv.vocab.keys())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = gensim.models.KeyedVectors.load_word2vec_format(pretrained_vectors, binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing new model with old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'lay', 'man', 'sermon', 'upon', 'late', 'storm', 'held', 'forth', 'at']\n"
     ]
    }
   ],
   "source": [
    "# model_2.build_vocab([list(model.vocab.keys())], update=True)\n",
    "print(list(model_2.wv.vocab.keys())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s>', '##', 'The', 'I', '####', '$', '###', 'It', 'He', 'We', 'In', 'A', 'U.S.', 'But', 'percent', '#.#', 'This', '#-#', 'They', \"'re\", '%', '#,###', 'By', '#.##', '1', 'If', 'And', '##,###', 'That', 'AP', 'There', \"'ve\", 'For', '2', '##.#', 'Friday', 'billion', 'Tuesday', 'Monday', 'She', 'Thursday', '###,###', 'Wednesday', 'You', 'As', '3', \"'m\", 'program', 'Saturday', 'American', '##-##', 'State', 'pm', 'Sunday', '&', '5', '##th', 'New_York', 'financial', '4', 'When', '##.##', 'On', \"'ll\", 'With', 'County', '#:##', 'At', 'March', 'City', 'May', 'University', 'After', 'June', 'China', 'John', '6', 'To', 'April', '7', 'One', 'United_States', 'Inc.', 'Department', 'All', 'National', 'So', 'data', 'New', 'July', 'President', 'Company', '8', 'What', 'Iraq', 'Police', 'Obama', 'Washington', 'However', 'America']\n"
     ]
    }
   ],
   "source": [
    "print(list(model_2.wv.vocab.keys())[27747:27747+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.intersect_word2vec_format(pretrained_vectors, binary=True, lockf=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3156347, 4206920)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.train(x, total_examples=total_examples, epochs=5,report_delay=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path=\"sg_pret_emb300_ep5.pkl\"\n",
    "utils.dump_pickle(model_2,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f7dfca040f0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = FastText(min_count=1,workers=4,min_n=1)\n",
    "model2.build_vocab(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93093, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.corpus_count,model2.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.train(x, total_examples=model2.corpus_count, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"fsttxt_emb100_ep40.pkl\"\n",
    "utils.dump_pickle(model2,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
